# Limpieza y manipulación de datos

## Objetivos

En esta lección aprenderemos:

- Que es la estrategia Divida-Aplique-Combine y como se utiliza con datos
- La diferencia entre los formatos de tablas anchas vs. largas y como convertir de un formato al otro
- Como usar `dplyr` y `tidyr` para limpiar y manipular datos para análisis
- Como unir múltiples `data.frame` usando `dplyr`

## Introducción

Es muy raro que recibamos datos para trabajar que esten en el formato que los necesitamos para hacer 
los análisis. Ocurre mucho que algunos paquetes de R requieren los datos en unformato, mientras otros
paquetes lo queres en otro. De esta forma, para ser analistas efectivos, debemos tener buenas herramientas
para re-formatear datos a las necesidades actuales del trabajo a realizar. Los paquetes de R `dplyr` y
`tidyr` entregan funciones muy completas y potentes para realizar este reformates en forma 
rápida y eficiente. Aprender a usar estas herramientas lo harán significativamente más eficiente.

Los análsis toman muchas formas, pero generlamente se pueden clasificar en lo que se conoce como la 
estrategia Divida-Aplique-Combine (Split-Apply-Combine).
Esta estrategoia sigue un set de pasos típicos:

- **Divida**: Dividir los datos en grupos lógicos (ej. área, stock, año)
- **Aplique:** Cálculo de estadísticas resumenes para cada grupo (ej. promedio del largo total por año)
- **Combine:** Combinación de los grupos en una tabla única

```{r splitApply, echo=FALSE, out.width = '100%', fig.align = 'center', fig.cap = 'Diagrama de la estragegia divida, aplique y combine.'}
knitr::include_graphics("images/8.1_split-apply-combine-diagram.png")
```

Como se muestra mas arriba (Figura \@ref(fig:splitApply), la tabla original se dividió en grupos
anuales (`year`), se calculó el largo promedio para cada grupoy finalmente se combinó en una
tabla única que incluye los primedios aunales en ella.

`dplyr` provides a fast and powerful way to express this.
Let's look at a simple example of how this is done:

Asumiendo que nuestrdos datos de largo estan cargados en un `data.frame` llamdo `length_data`:

| year| length_cm|
|----:|---------:|
| 1991|  5.673318|
| 1991|  3.081224|
| 1991|  4.592696|
| 1992|  4.381523|
| 1992|  5.597777|
| 1992|  4.900052|
| 1992|  4.139282|
| 1992|  5.422823|
| 1992|  5.905247|
| 1992|  5.098922|

Podemo hacer el cálculo usando `dplyr` así:

```{r, eval = FALSE}
length_data %>% 
  group_by(year) %>% 
  summarise(mean_length_cm = mean(length_cm))
```

Otra actividad muy común que es necesario hacer es cambiar la forma de las tablas con 
datos ("_reshape_"). Vamos un ejemplo de una tabla en el formato, que de ahora en adelante
llamaremos, "_ancho_":


| site   | 1990 | 1991 | ... | 1993 |
|--------|------|------|-----|------|
| gold   | 100  | 118  | ... | 112  |
| lake   | 100  | 118  | ... | 112  |
| ...    | ...  | ...  | ... | ...  |
| dredge | 100  | 118  | ... | 112  |

Es muy probable que usted esté familiarizado con datos en este tipo de formato, donde los valores de
las variables obsercadas estan reparticos en mas de una columna (en este caso, columnas para cada 
año). Otra forma de describir esto es qeue existe más de una medición por cada fila. Este formato
anchivo funciona muy bien para la entrada de datos y a veces para algunos análisis, pero se hace
rápidamente inutil en R. Por ejemplo, ¿cómo puede ajustar un modelo con el año como una variable
predictora? en un mundo ideakm deberiamos poder ejecutar la siguiente línea de código:

```{r eval = FALSE}
lm(length ~ year)
```

Pero esto no va a funcionar en una tabla con formado ancho, `lm` necesita `length` y 
`year` como columnas de la tabla para funcionar.

¿Cómo podemos hacer un gráfico para cada año?
Se puede llamar a la función `plot` una vez para cada año, pero esto es tedioso, especialmente 
si hay muchos años en los datos, además se hace dificil mantener el código y agregar más años 
a nuestro set de datos-.

El paquete `tidyr` nos permite rápidamente cambiar entre formato ancho y formato largo utilizando
la función `gather`:

```{r, eval=FALSE}
site_data %>% 
  gather(year, length, -site)
```

| site   | year | length |
|--------|------|-------:|
| gold   | 1990 |    101 |
| lake   | 1990 |    104 |
| dredge | 1990 |    144 |
| ...    | ...  |    ... |
| dredge | 1993 |    145 |

En esta clase va mos a aprender a usar las funciones más comunes de los paquetes `dplyr`
y `tidyr`:

- `dplyr`
    - `mutate()`
    - `group_by()`
    - `summarise()`
    - `select()`
    - `filter()`
    - `arrange()`
    - `left_join()`
    - `rename()`
- `tidyr`
    - `gather()`
    - `spread()`
    - `extract()`
    - `separate()`

## Configurgación (Setup)

Vamos a comenzar con las funciones más comunies del paquete `dplyr`.
Para demostrar como se usan, vamos a trabajar con una versión de un set de datos ya 
pre-ordenado del Departamento de Pesca y Caza de Alaska (ADF&G) que contiene los datos 
de capturas comerciales de 1878 a 1997.
El set de datos y su referencia a la fuente original se puede encontrar en el siguiente 
archivo público: https://knb.ecoinformatics.org/#view/df35b.304.2.

Primero, vamos a leer los paquetes `dplyr` y `tidyr`:

```{r, message = F, warning = F}
library(dplyr)
library(tidyr)
```

Aohra tenemos que lees los datos y darle una mirada:

```{r, cache=TRUE}
catch_original <- read.csv(url("https://knb.ecoinformatics.org/knb/d1/mn/v2/object/df35b.302.1", method = "libcurl"),
                    stringsAsFactors = FALSE)
head(catch_original)
```

Nota: para descargar los datos, copié el URL desde el botón de descarga (Download) en 
https://knb.ecoinformatics.org/#view/df35b.304.2

Este dataset estpá relativamente limpio y es de fácil interpretación.
Si bien estos datos están limpios, el formato de la tabla hace que sea dificil usarlos 
para alguno de los análisis que debemos realizar. Como primer paso tenemos que arreglar eso.

## Acerca del operador de pipe (tubo; `%>%`)

Antes de comenzar a aprender sobre `tidyr` y `dplyr` es necesarios que explique de que se trata el `%>%`.

Tanto el paquete `tidyr` como `dplyr` usa el operador `%>%`. Este operador es una forma muy 
eficiente para encadenar operaciones. Esta tubería toma la salida de una operación anterior y la
entrega como una entrada a la siguiente.

Digamoas que quiere filtrar `filter` unas filas y seleccionar `select` una columnas de la misma tabla
de datos. Para esto se puede usar

```
df_filtered <- filter(df, ...)
df_selected <- select(df_filtered, ...)
```

Sin embargo, su código será más simple y eficiente (más rápido con set de datos grandes!)

```
df_cleaned <- df %>% 
              filter(...) %>%
              select(...)
```

Si usted pensa en el operador de asignación (`<-`) como "recibe", entonces el operador _pipe_
se puede leer como "entonces".

Entonces, el fragmento de código anterior se puede traducir como:

El dataframere limpio recive los datos originales, _entonces_ realiza un filtro (de los datos 
originales) y _entonces_ selecciona (sobre los datos filtrados).

El beneficio de usar _pipes_ es que no es necesario seguir el rastro (o de sobre-escribir) de 
set de datos intermedios. El costo es que se hace un poco mas dificil de explicar el razonamiento
de cada paso, espcialmente cuando existen muchas operaciones encadenadas. Lo ideal es tener un 
balance entre escribir códigos eficientes (operaciones encadenadas) y que sean legibles e 
interpretables, tanta para uno en el futuro, como para que otros puedan entender la lógica de
que y por qué se hizo lo que se hizo.

RStudio tiene una combinación de teclas para `%>%` : Ctrl + Shift + M (Windows), Cmd + Shift + M (Mac).

## Seleccionar/remover columnas: `select()`

El primer problemas con los datos son las columnas `All` y `notesRegCode`.
Vamos a seleccionar sólo las columnas con las que queremos trabajar y las vamos a asignar 
a la variable llamada `catch_data`.

```{r}
catch_data <- catch_original %>% 
  select(Region, Year, Chinook, Sockeye, Coho, Pink, Chum)

head(catch_data)
```

Esto está mucho mejor.

`select` nos permite indicar las columnas que **no** queremos, para esto solo tenemos que
pasar las columnas (sin comillas) con un signo menos (-):

```{r}
catch_data <- catch_original %>% 
  select(-All, -notesRegCode)

head(catch_data)
```

## Cambiar el formato: `gather()` y `spread()`

El siguiente punto problema con los datos es que están en un formato ancho y que para
trabajar lo necesitamos en uno largo.
`gather()` del parquete `tidyr` nos ayuda a hacer esta conversión:

```{r}
catch_long <- catch_data %>% 
  gather(species, catch, -Region, -Year)

head(catch_long)
```

La sintaxis que usarmos para `gather()` puede ser un poco confusa, asi que vamos a explicarlo con el 
diagrama rotulado de la figura \@ref(fig:annotatedGather):


```{r annotatedGather, echo=FALSE, out.width = '100%', fig.align = 'center', fig.cap = 'Diagrama rotulado donde se explica cada uno de los inputs a la función gather.'}
knitr::include_graphics("images/8.2_gather_annotated.png")
```

Los primeros dos argumentos de la función `gather()` son los nombres de las columnas unevas que 
serán creados y los otros argumentos con el símbolo `-` son las columnas que se deben mantener
en el proceso. La función opuesta a `gather()` es `spread()`, funciona la misma forma declarativa:

```{r}
catch_wide <- catch_long %>% 
  spread(species, catch)

head(catch_wide)
```

## Renombrando columnas con `rename()`

If you scan through the data, you may notice the values in the `catch` column are very small (these are supposed to be annual catches).
If we look at [the metadata](https://knb.ecoinformatics.org/#view/df35b.304.2) we can see that the `catch` column is in thousands of fish so let's convert it before moving on.

Let's first rename the `catch` column to be called `catch_thousands`:

```{r}
catch_clean <- catch_long %>% 
  rename(catch_thousands = catch)

head(catch_clean)
```

## Adding columns: `mutate()`

Now let's create a new column called `catch` with units of fish (instead of thousands of fish). Note that here we have added to the expression we wrote above by adding another function call (`mutate`) to our expression. This takes advantage of the pipe operator by grouping together a similar set of statements, which all aim to clean up the `catch_long` `data.frame`.

```{r, eval=FALSE}
catch_clean <- catch_long %>% 
  rename(catch_thousands = catch) %>%
  mutate(catch = catch_thousands * 1000)

head(catch_clean)
```

You'll notice that we get an error:

> Error in mutate_impl(.data, dots) : Evaluation error: non-numeric argument to binary operator.

This is an extremely cryptic error -- what is it telling us?
These kinds of errors can be very hard to diagnose, but maybe the `catch` column isn't quite what we are expecting.
How could we find out?
R provides a number of handy utility functions for quickly summarizing a large table:

```{r}
summary(catch_clean)
```

- **Exercise:** What are some other ways (functions) we could've found out what our problem was?

Notice in the above output that the `catch_thousands` column shows up as `Class :character`.
That seems wrong since catch should be whole numbers (in R, these show up as integers).

Let's try to convert the values to integers and see what happens:

```{r}
catch_integers <- as.integer(catch_clean$catch_thousands)
```

We get an error "NAs introduced by coercion" which is R telling us that it couldn't convert every value to an integer and, for those values it couldn't convert, it put an `NA` in its place.
This is behavior we commonly experience when cleaning datasets and it's important to have the skills to deal with it when it crops up.
We can find out which values are NAs with a combination of `is.na()` and `which()`, and save that to a variable called `i`.

```{r}
i <- which(is.na(catch_integers))
i
```

It looks like there is only one problem row, lets have a look at it:

```{r}
catch_clean[i,]
```

Well that's odd: The value in `catch_thousands` is `I` which is isn't even a number.
It turns out that this dataset is from a PDF which was automatically converted into a CSV and this value of `I` is actually a 1.
Let's fix it:

```{r}
catch_clean <- catch_long %>% 
  rename(catch_thousands = catch) %>%
  mutate(catch_thousands = ifelse(catch_thousands == "I", 1, catch_thousands)) %>%
  mutate(catch_thousands = as.integer(catch_thousands))

head(catch_clean)
```

Note that, in the above pipeline call to `mutate()`, we mutate `catch_thousands` twice.
This works because `mutate()` processes each of the mutations in a step-wise fashion so the results of one mutation are available for the next.

Now let's try our conversion again by adding it as another function call in our expression.

```{r}
catch_clean <- catch_long %>% 
  rename(catch_thousands = catch) %>%
  mutate(catch_thousands = ifelse(catch_thousands == "I", 1, catch_thousands)) %>%
  mutate(catch_thousands = as.integer(catch_thousands)) %>% 
  mutate(catch = catch_thousands * 1000)

head(catch_clean)
```

Looks good, no warnings!
Now let's remove the `catch_thousands` column for now since we don't need it:

```{r}
catch_clean <- catch_long %>% 
  rename(catch_thousands = catch) %>%
  mutate(catch_thousands = ifelse(catch_thousands == "I", 1, catch_thousands)) %>%
  mutate(catch_thousands = as.integer(catch_thousands)) %>% 
  mutate(catch = catch_thousands * 1000) %>% 
  select(-catch_thousands)    

head(catch_clean)
```

We're now ready to start analyzing the data.

## `group_by` and `summarise`

As I outlined in the Introduction, `dplyr` lets us employ the Split-Apply-Combine strategy and this is exemplified through the use of the `group_by()` and `summarise()` functions:

```{r}
mean_region <- catch_clean %>% 
  group_by(Region) %>%
  summarise(mean(catch))

head(mean_region)
```

- **Exercise:** Find another grouping and statistic to calculate for each group.
- **Exercise:** Find out if you can group by multiple variables.

Another common use of `group_by()` followed by `summarize()` is to count the number of rows in each group.
We have to use a special function from `dplyr`, `n()`.

```{r}
n_region <- catch_clean %>% 
  group_by(Region) %>%
  summarize(n = n())

head(n_region)
```

## Filtering rows: `filter()`

`filter()` is the verb we use to filter our `data.frame` to rows matching some condition.
It's similar to `subset()` from base R.

Let's go back to our original `data.frame` and do some `filter()`ing:

```{r}
SSE_catch <- catch_clean %>% 
  filter(Region == "SSE")

head(SSE_catch)
```

- **Exercise:** Filter to just catches of over one million fish.
- **Exercise:** Filter to just SSE Chinook

## Sorting your data: `arrange()`

`arrange()` is how we sort the rows of a `data.frame`.
In my experience, I use `arrange()` in two common cases:

- When I want to calculate a cumulative sum (with `cumsum()`) so row order matters
- When I want to display a table (like in an `.Rmd` document) in sorted order

Let's re-calculate mean catch by region, and then `arrange()` the output by mean catch:

```{r}
mean_region <- catch_clean %>% 
  group_by(Region) %>% 
  summarise(mean_catch = mean(catch)) %>% 
  arrange(mean_catch)

head(mean_region)
```

The default sorting order of `arrange()` is to sort in ascending order.
To reverse the sort order, wrap the column name inside the `desc()` function:

```{r}
mean_region <- catch_clean %>% 
  group_by(Region) %>% 
  summarise(mean_catch = mean(catch)) %>% 
  arrange(desc(mean_catch))

head(mean_region)
```

## Joins in dplyr

So now that we're awesome at manipulating a single `data.frame`, where do we go from here?
Manipulating **more than one** `data.frame`.

If you've ever used a database, you may have heard of or used what's called a "join", which allows us to to intelligently merge two tables together into a single table based upon a shared column between the two.
We've already covered joins in [Data Modeling & Tidy Data] so let's see how it's done with `dplyr`.

The dataset we're working with, https://knb.ecoinformatics.org/#view/df35b.304.2, contains a second CSV which has the definition of each `Region` code.
This is a really common way of storing auxiliary information about our dataset of interest (catch) but, for analylitcal purposes, we often want them in the same `data.frame`.
Joins let us do that easily. 

Let's look at a preview of what our join will do by looking at a simplified version of our data:

![Visualisation of our `left_join`](images/left_join_catchdata.png)


First, let's read in the region definitions data table and select only the columns we want. Note that I have piped my `read.csv` result into a select call, creating a tidy chunk that reads and selects the data that we need.


```{r, cache=TRUE}
region_defs <- read.csv(url("https://knb.ecoinformatics.org/knb/d1/mn/v2/object/df35b.303.1",
                            method = "libcurl"),
                        stringsAsFactors = FALSE) %>% 
    select(code, mgmtArea)

head(region_defs)
```


If you examine the `region_defs` `data.frame`, you'll see that the column names don't exactly match the image above. If the names of the key columns are not the same, you can explicitly specify which are the key columns in the left and right side as shown below:

```{r}
catch_joined <- left_join(catch_clean, region_defs, by = c("Region" = "code"))

head(catch_joined)
```

Notice that I have deviated from our usual pipe syntax (although it does work here!) because I prefer to see the `data.frames` that I am joining side by side in the syntax.

Another way you can do this join is to use `rename` to change the column name `code` to `Region` in the `region_defs` `data.frame`, and run the `left_join` this way:

```{r, eval = F}
region_defs <- region_defs %>% 
  rename(Region = code, Region_Name = mgmtArea)

catch_joined <- left_join(catch_clean, region_defs, by = c("Region"))

head(catch_joined)
```



Now our catches have the auxiliary information from the region definitions file alongside them.
Note: `dplyr` provides a complete set of joins: inner, left, right, full, semi, anti, not just left_join.

## `separate()` and `unite()`

`separate()` and its complement, `unite()` allow us to easily split a single column into numerous (or numerous into a single).
This can come in really handle when we have a date column and we want to group by year or month.
Let's make a new `data.frame` with fake data to illustrate this:

```{r}
dates_df <- data.frame(date = c("5/24/1930",
                                "5/25/1930",
                                "5/26/1930",
                                "5/27/1930",
                                "5/28/1930"),
                       stringsAsFactors = FALSE)

dates_df %>% 
  separate(date, c("month", "day", "year"), "/")
```

- **Exercise:** Split the `city` column in the following `data.frame` into `city` and `state_code` columns:

```{r}
cities_df <- data.frame(city = c("Juneau AK", 
                                 "Sitka AK", 
                                 "Anchorage AK"),
                        stringsAsFactors = FALSE)

# Write your solution here
```

`unite()` does just the reverse of `separate()`:

```{r}
dates_df %>% 
  separate(date, c("month", "day", "year"), "/") %>% 
  unite(date, month, day, year, sep = "/")
```

- **Exercise:** Use `unite()` on your solution above to combine the `cities_df` back to its original form with just one column, `city`:

```{r}
# Write your solution here
```

## Summary

We just ran through the various things we can do with `dplyr` and `tidyr` but if you're wondering how this might look in a real analysis.
Let's look at that now:

```{r, catch=TRUE}
catch_original <- read.csv(url("https://knb.ecoinformatics.org/knb/d1/mn/v2/object/df35b.302.1", method = "libcurl"),
                  stringsAsFactors = FALSE)
region_defs <- read.csv(url("https://knb.ecoinformatics.org/knb/d1/mn/v2/object/df35b.303.1", method = "libcurl"),
                        stringsAsFactors = FALSE) %>% 
    select(code, mgmtArea)

mean_region <- catch_original %>%
  select(-All, -notesRegCode) %>% 
  gather(species, catch, -Region, -Year) %>%
  mutate(catch = ifelse(catch == "I", 1, catch)) %>% 
  mutate(catch = as.integer(catch)*1000) %>% 
  group_by(Region) %>% 
  summarize(mean_catch = mean(catch)) %>% 
  left_join(region_defs, by = c("Region" = "code"))

head(mean_region)
```
